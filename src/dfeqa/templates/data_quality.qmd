---
title: -_{{report_title}}_-
author: ~~your name here~~
date: last-modified
format:
    html:
        code-fold: true
        embed-resources: true
        toc: true
        toc-location: left
jupyter: python3
editor: source
execute: 
  warning: false
  message: false
---
# {{report_title}}

## Introduction

Add some introductory test stating the purpose and context of the data as well as introducing the report.

The dimensions of data quality listed below are explained on more detail in the [DQHub website](https://www.gov.uk/government/publications/the-government-data-quality-framework/the-government-data-quality-framework#Data-quality-dimensions).

Any additional information about processes that will resolve issues reported in this document can go here at a high-level. Specific actions to address particular issues may be better placed with the analysis reported below.

It is a good idea to reference organsiational goals at this point. Use visualisations to relate the quality of the data being reported on back to those goals. These don't have to be charts, but make use of being able to include pngs, or generate mermaid diagrams.

```{python}
#| echo: false
    # load data and import any modules required
    import pandas as pd
    from dfeqa import load_census, fd, freqchart
    df = load_census(202324, NCYear = "R", term = "Autumn", columns = ["AcademicYear", "CensusTerm", "URN", "DOB", "UPN"])
    reference = load_census(202223, NCYear = "R", term = "Autumn", columns = ["AcademicYear", "CensusTerm", "URN", "DOB", "UPN"])

```

## Data Quality Reporting

### Completeness

Completeness describes the degree to which records are present.

```{python}
#| label: fig-completeness
#| fig-cap: "Completeness of data: comparison with data from the previous year"

chartdata = pd.DataFrame([
    {'year':'this_year', 'record count':df.shape[0]},{'year':'last_year', 'record count':reference.shape[0]}
    ])
freqchart(chartdata = chartdata, value_col = 'record count',freq_col = 'year')

```

### Uniqueness

Uniqueness describes the degree to which there is no duplication in records. This means that the data contains only one record for each entity it represents, and each value is stored once.

```{python}
#| label: fig-uniqueness
#| fig-cap: "Uniqueness of data: comparison with data from the previous year"

chartdata = pd.DataFrame([
    {'year':'this_year', 'record count':df['UPN'].nunique() / df.shape[0]},
    {'year':'last_year', 'record count':reference['UPN'].nunique() / reference.shape[0]}
    ])
freqchart(chartdata = chartdata, value_col = 'proportion unique',freq_col = 'year')

```

### Consistency

Consistency describes the degree to which values in a data set do not contradict other values representing the same entity. For example, a mother’s date of birth should be before her child’s.



### Timeliness

Timeliness describes the degree to which the data is an accurate reflection of the period that they represent, and that the data and its values are up to date.

This dataset refers to a census where the data reflects a point in time - this should not change. Other datasets will benefit from analyses to monitor change or reference datasets collected at different times.

### Validity

Validity describes the degree to which the data is in the range and format expected. For example, date of birth does not exceed the present day and is within a reasonable range.

This could easily be the biggest section of the report if handled badly. Ideally this section should report by exception - the failures, or an overview (all 500 columns contain values within specified range) and refer to appendices for detail.

### Accuracy

Accuracy describes the degree to which data matches reality.

### User needs and trade-offs

Are there any hot-topics or issues which have occurred in the past which require monitoring?

## Interpretation, conclusion and recommendation

In summary, what does it all mean? What purposes can the data be used for?

## Appendices

Lists of columns, tables, metadata, etc.
